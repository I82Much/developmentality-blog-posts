# DAWG or DAWG not.  There is no Trie.

## Solving Scramble with Friends - Recursion, Stacks, and Tries

Apologies to Yoda, and to you for having to read such a bad pun.  This post aims to illustrate how to solve Scramble With Friends/Boggle and the techniques and data structures necessary.  In particular, we will see how to prune an enormous search space, how to use recursion to simplify the task, as well as the relative performance of three different data structures and implementations.

# Problem statement
Given an N x N board, (4x4 in case of Boggle and Scramble with Friends), find all of the paths through the board which create a valid word.  These paths are constrained to 1) use each tile at most once and 2) be contiguous; tile N must be adjacent to tile N - 1 in any of 8 directions (North, Northeast, East, Southeast, South, Southwest, West, Northwest).

![Scramble Screenshot][]

In this example, 

# Naivest approach

First, imagine that we have a method that, given a path through the board returns all valid words that starts with that path, called DoSolve.  For instance, DoSolve(['Qu']) would return all the valid words (and their locations) that start with Qu.  DoSolve(['N', 'E']) would return all the valid paths that start with N followed by an E.  With such a method, it is trivial to solve the problem.  In pseudocode:

	Solve(board):
		solutions = empty list
		for each location on board:
			append DoSolve(location) to solutions
		return solutions
	
The tricky part is, how do we make DoSolve work?  Remember that it must 1) return only valid words 2) return only words that are formed from contiguous tiles and 3) must not repeat any tiles.

The easiest way to solve this problem is through recursion. As you probably remember, [recursion][Recursion] is simply when a method calls itself.  In order to avoid an infinite loop (and eventual stack overflow), there must be some sort of stopping criteria.  As it was taught to me, you have to be sure that the problem becomes smaller at each step, until it becomes so small as to be trivially solved.  Here's that basic algorithm:

	DoSolve(board, tiles_used)
		solutions = empty list

		current word = empty string
		for letter in tiles_used:
			append letter to current word

		# 1 - ensure that the word is valid
		if the current word is a valid word:
			append current word to solutions
		
		most recent tile = last tile in tiles_used

		# 2 - ensure that the next tile we use is adjacent to the last one
		for each tile adjacent to most recent tile:
		
			# 3 - ensure that we do not repeat any tiles
			if tile is on the board and tile hasn't been used previously:
				new_path = append tile to copy of tiles_used list
				solutions_starting_from_tile = DoSolve(board, new_path)
				append solutions_starting_from_tile to solutions
			
		return solutions

This will work, but it suffers from an incredible flaw.  Do you see it?

The problem is that this method will waste an inordinate amount of time exhaustively searching the board for solutions even when the current path is completely useless.  It will continue to search for words starting with QuR, QuRE, etc., etc., even though no words in the English language start with these letters.  The algorithm is still correct, but it can be optimized very simply.

# Pruning the search space

Those with some algorithms background might recognize the code above as a modified form of a [depth first search][].  As described previously, a depth first search will exhaustively explore every possible path through the board.  We can vastly improve the efficiency of this algorithm by quitting the search early when we know it won't be fruitful.  If we know all of the valid words, we can quit when we know that no  word starts with the current string.  Thus in the previous example, if the current word built up so far were "QuR", the algorithm could determine that no words start with QuR and thus fail fast and early.  This optimization will not affect the correctness of the algorithm because none of the potential paths we eliminate could possibly lead to a valid word; by constraint #1 this means that none of those paths would have ended up in the list of solutions in the first place.

# TODO(ndunn): Include information about how much time this saves

# Basic Python implementation

Assume as a black box we have two methods IsWord(string) and HasPrefix(string).  The pseudocode above can be expressed with Python (forgive the slightly modified parameter list; I found it easier to write it this way):

<div>
[sourcecode language="python"]
def DoSolve(self, board, previous_locations, location, word_prefix):
"""Returns iterable of FoundWord objects.

Args:
  previous_locations: a list of already visited locations
  location: the current Location from where to start searching
  word_prefix: the current word built up so far, as a string
"""
solutions = []

new_word = word_prefix + board[location.row][location.col]
previous_locations.append(location)

if PREFIX_PRUNE and not self.HasPrefix(new_word):
  if DEBUG:
    print 'No words found starting with "%s"' %(new_word)
  return solutions

# This is a valid, complete words.
if self.IsWord(new_word):
  new_solution = FoundWord(new_word, previous_locations)
  if DEBUG:
    print 'Found new solution: %s' %(str(new_solution))
  solutions.append(new_solution)

# Recursively search all adjacent tiles
for new_loc in location.Adjacent():
  if board.IsValidLocation(new_loc) and new_loc not in previous_locations:
    # make a copy of the previous locations list so our current list
    # is not affected by this recursive call.
    defensive_copy = list(previous_locations)
    solutions.extend(self.DoSolve(board, defensive_copy, new_loc, new_word))
  else:
    if DEBUG:
      print 'Ignoring %s as it is invalid or already used.' %(str(new_loc))

return solutions

[/sourcecode]
</div>

# Data structures
The data structure and algorithms used to implement the IsWord and HasPrefix methods are incredibly important.  

I will examine three implementations and discuss the performance characteristics of each:

* Unsorted list
* Sorted list with binary search
* Trie

# Unsorted list

An unsorted list is a terrible data structure to use for this task.  Why?  Because it leads to running time proportional to the number of elements in the word list.  

<div>
[sourcecode language="python"]
class UnsortedListBoardSolver(BoardSolver):
  def __init__(self, valid_words):
    self.valid_words = valid_words

  def HasPrefix(self, prefix):
    for word in self.valid_words:
      if word.startswith(prefix):
        return True
    return False

  def IsWord(self, word):
    return word in self.valid_words
[/sourcecode]
</div>

While this is easy to understand and reason about, it is extremely slow, especially for a large dictionary (I used approximately 200k words for testing).

	Took 207.697 seconds to solve 1 boards; avg 207.697 with <__main__.UnsortedListBoardSolver object at 0x135f170>

# Sorted list

Since we know the valid words ahead of time, we can take advantage of this fact and sort the list.  With a sorted list, we can perform a [binary search][Binary search] and cut our running time from O(n) to O(log n).

Writing a binary search from scratch is very error prone; in his classic work Programming Pearls, Jon Bently claims that fewer than 10% of programmers can implement it correctly.  (See [blog post][binary search blog post] for more).

Fortunately, there's no reason whatsoever to write our own binary search algorithm.  Python's standard library already has an implementation in its [bisect module][].  Following the example given in the module documentation, we get the following implementation:

<div>
[sourcecode language="python"]
class SortedListBoardSolver(BoardSolver):
  def __init__(self, valid_words):
    self.valid_words = sorted(valid_words)

  # http://docs.python.org/library/bisect.html#searching-sorted-lists
  def index(self, a, x):
    'Locate the leftmost value exactly equal to x'
    i = bisect.bisect_left(a, x)
    if i != len(a) and a[i] == x:
      return i
    raise ValueError
  
  def find_ge(self, a, x):
    'Find leftmost item greater than or equal to x'
    i = bisect.bisect_left(a, x)
    if i != len(a):
      return a[i]
    raise ValueError  

  def HasPrefix(self, prefix):
    try:
      word = self.find_ge(self.valid_words, prefix)
      return word.startswith(prefix)
    except ValueError:
      return False
    
  def IsWord(self, word):
    try:
      self.index(self.valid_words, word)
    except ValueError:
      return False
    return True
[/sourcecode]
</div>

Running the same gauntlet of tests, we see that this data structure performs far better than the naive, unsorted list approach.

	Took 0.094 seconds to solve 1 boards; avg 0.094 with <__main__.SortedListBoardSolver object at 0x135f1d0>
	Took 0.361 seconds to solve 10 boards; avg 0.036 with <__main__.SortedListBoardSolver object at 0x135f1d0>
	Took 2.622 seconds to solve 100 boards; avg 0.026 with <__main__.SortedListBoardSolver object at 0x135f1d0>
	Took 25.065 seconds to solve 1000 boards; avg 0.025 with <__main__.SortedListBoardSolver object at 0x135f1d0>


# Trie

The final data structure I want to illustrate is that of the trie.  The [Wikipedia article][Trie wikipedia] has a lot of great information about it.  

![Trie image](http://upload.wikimedia.org/wikipedia/commons/thumb/b/be/Trie_example.svg/400px-Trie_example.svg.png)

From Wikipedia:

> In computer science, a trie, or prefix tree, is an ordered tree data structure that is used to store an associative array where the keys are usually strings. Unlike a binary search tree, no node in the tree stores the key associated with that node; instead, its position in the tree defines the key with which it is associated. All the descendants of a node have a common prefix of the string associated with that node, and the root is associated with the empty string. Values are normally not associated with every node, only with leaves and some inner nodes that correspond to keys of interest.

Snip:

>Looking up a key of length m takes worst case O(m) time. A BST performs O(log(n)) comparisons of keys, where n is the number of elements in the tree, because lookups depend on the depth of the tree, which is logarithmic in the number of keys if the tree is balanced. Hence in the worst case, a BST takes O(m log n) time. Moreover, in the worst case log(n) will approach m. Also, the simple operations tries use during lookup, such as array indexing using a character, are fast on real machines

Again, I don't want to reinvent what's already been done before, so I will be using [Jeethu Rao's implementation][Python trie implementation] of a trie in Python rather than rolling my own.

Here is a demonstration of its API via the interactive prompt:

	>>> import trie
	>>> t = trie.Trie()
	>>> t.add('hell', 1)
	>>> t.add('hello', 2)
	>>> t.find_full_match('h')
	>>> t.find_full_match('hell')
	1
	>>> t.find_full_match('hello')
	2
	>>> t.find_prefix_matches('hello')
	[2]
	>>> t.find_prefix_matches('hell')
	[2, 1]
	
Unfortunately, there's a bug in his code:

	>>> t = trie.Trie()
	>>> t.add('hello', 0)
	>>> 'fail' in t
	False
	>>> 'hello' in t
	True
	# Should be false; 'h' starts a string but
	# it is not contained in data structure
	>>> 'h' in t
	True
	
His `__contains__` method is as follows:

	def __contains__( self, s ) :
	  if self.find_full_match(s,_SENTINEL) is _SENTINEL :
	      return False
	  return True

The `find_full_match` is where the problem lies.

	def find_full_match( self, key, fallback=None ) :
      '''
      Returns the value associated with the key if found else, returns fallback
      '''
      r = self._find_prefix_match( key )
      if not r[1] and r[0]:
        return r[0][0]
      return fallback
	
`_find_prefix_match` returns a tuple of node that the search terminated on, remainder of the string left to be matched.  For instance,

	>>> t._find_prefix_match('f')
	[[None, {'h': [None, {'e': [None, {'l': [None, {'l': [None, {'o': [0, {}]}]}]}]}]}], 'f']
	>>> t.root
	[None, {'h': [None, {'e': [None, {'l': [None, {'l': [None, {'o': [0, {}]}]}]}]}]}]

This makes sense, 'f' doesn't start any words in the trie containing just the word 'hello', so the root is returned with the 'f' string that doesn't match.  `find_full_match` correctly handles this case, since r[1] = 'f', not r[1] = False, and the fallback is returned.  That fallback is used by contains to signify that the given string is *not* in the trie.

The problem is when the string in question starts a valid string but is itself not contained in the trie.  As we saw previously, 'h' is considered to be in the trie.

	>>> r = t._find_prefix_match('h')
	>>> r
	[[None, {'e': [None, {'l': [None, {'l': [None, {'o': [0, {}]}]}]}]}], '']
	>>> r[0]
	[None, {'e': [None, {'l': [None, {'l': [None, {'o': [0, {}]}]}]}]}]
	>>> r[1]
	''
	>>> bool(not r[1] and r[0])
	True
	>>> r[0][0]
	# None
	
	The issue is that his code does not check that there is a value stored in the given node.  Since no such value has been stored, the code returns None, which is not equal to the SENTINEL_ value that his `__contains__` method expects.  We can either change find_full_match to handle this case correctly, or change the `__contains__` method to handle the None result as a failure.  Let's modify the `find_full_match` method to obey it's implied contract (and be easier to understand):
	
	def find_full_match( self, key, fallback=None ) :
      '''
      Returns the value associated with the key if found else, returns fallback
      '''
      curr_node, remainder = self._find_prefix_match(key)
	  stored_value = curr_node[0]
	  has_stored_value = stored_value is not None
	  if not remainder and has_stored_value:
		return stored_value
	  return fallback

Let's make sure this works:

	>>> reload(trie)
	<module 'trie' from 'trie.py'>
	>>> t = trie.Trie()
	>>> t.add('hello', 2)
	>>> 'f' in t
	False
	>>> 'hell' in t
	False
	>>> 'hello' in t
	True


OK, with that minor patch, here's a first pass implementation of the solution using the trie:

<div>
[sourcecode language="python"]
class TrieBoardSolver(BoardSolver):
  def __init__(self, valid_words):
    self.trie = trie.Trie()
    for index, word in enumerate(valid_words):
      # 0 evaluates to False which screws up trie lookups; ensure value is 'truthy'.
      self.trie.add(word, index+1)
  
  def HasPrefix(self, prefix):
    return len(self.trie.find_prefix_matches(prefix)) > 0

  def IsWord(self, word):
    return word in self.trie
[/sourcecode]
</div>

Unfortunately, this is slow.  How slow?

	Took 2.626 seconds to solve 1 boards; avg 2.626 with <__main__.TrieBoardSolver object at 0x135f070>
	Took 22.681 seconds to solve 10 boards; avg 2.268 with <__main__.TrieBoardSolver object at 0x135f070>

While this isn't as bad as the unsorted list, it's still orders of magnitudes slower than the binary search implementation.


Why is this slow?  Well, it's doing a whole lot of unnecessary work.  For instance, if we want to determine if 'h' is a valid prefix, this implementation will first construct the list of *all* words that start with h, only to have all that work thrown away when we see that the list is not empty.

A much more efficient approach is to cheat a little and use an internal method `_find_prefix_match` which returns the node in the tree that the search stopped at and how much of the string was unmatched.  

<div>
[sourcecode language="python"]
>>> import trie
>>> t = trie.Trie()
>>> t.add('hell', 1)
>>> t.add('hello', 2)
>>> t._find_prefix_match('h')
# There is a prefix match, so the unmatched portion is the empty string
[[None, {'e': [None, {'l': [None, {'l': [1, {'o': [2, {}]}]}]}]}], '']
>>> t._find_prefix_match('a')
# No match, so the entire string is unmatched
[[None, {'h': [None, {'e': [None, {'l': [None, {'l': [1, {'o': [2, {}]}]}]}]}]}], 'a']
>>> t._find_prefix_match('help')
# Partial match, so part of the prefix string is returned
[[None, {'l': [1, {'o': [2, {}]}]}], 'p']
[/sourcecode]
</div>

By using this method directly, we can avoid creating the lists of words which we then throw away.  We modify the HasPrefix method to the following:

<div>
[sourcecode language="python"]
def HasPrefix(self, prefix):
  curr_node, remainder = self.trie._find_prefix_match(prefix)
  return not remainder
[/sourcecode]
</div>

With this optmization, the trie becomes competitive with the binary search:

	Took 0.073 seconds to solve 1 boards; avg 0.073 with <__main__.TrieBoardSolver object at 0x135f090>
	Took 0.243 seconds to solve 10 boards; avg 0.024 with <__main__.TrieBoardSolver object at 0x135f090>
	Took 3.641 seconds to solve 100 boards; avg 0.036 with <__main__.TrieBoardSolver object at 0x135f090>

It is still slower, but not nearly as bad as before.

# Conclusion

# TODO(ndunn): fix this busted bs.
>>> [x.word for x in trie_solutions if x not in sorted_solutions]
['ll', 'llu', 'lla', 'llan', 'qu', 'qur', 'reu', 'reus', 'reut', 'reuti', 'reutil', 'reuc', 'res', 'resu', 'resul', 'resulta', 'resultan', 'resulti', 'resultin', 'resui', 'resuin', 'resuc', 'resi', 'resil', 'resit', 'resic', 'resine', 'resc', 'rescu', 'resci', 'rescin', 'ru', 'rues', 'rul', 'rula', 'rulan', 'ruli', 'rulin', 'rusi', 'rusc', 'ruti', 'rutil', 'rutila', 'rutilan', 'rute', 'rui', 'ruine', 'ruc', 'ruce', 'rucer', 'erl', 'eru', 'eruci', 'eur', 'eul', 'eula', 'euli', 'eus', 'eusc', 'eut', 'euta', 'eutan', 'eutr', 'eute', 'eutec', 'euter', 'euc', 'euci', 'eucir', 'euce', 'eucn', 'eucne', 'esu', 'esur', 'esi', 'esc', 'escu', 'escul', 'escula', 'esculi', 'escut', 'escute', 'sl', 'squ', 'squu', 'squus', 'sl', 'slu', 'slus', 'slui', 'sluic', 'slati', 'slatis', 'slatin', 'slatine', 'slan', 'slanti', 'slantin', 'slar', 'sli', 'slis', 'slic', 'slir', 'slin', 'sall', 'salu', 'salut', 'saluti', 'saltu', 'salti', 'saltis', 'saltie', 'saltin', 'saltn', 'salte', 'sali', 'salis', 'salit', 'salice', 'salicet', 'salicetu', 'salie', 'salien', 'salienc', 'salin', 'satl', 'satli', 'satu', 'satur', 'sature', 'sati', 'satis', 'satir', 'satie', 'satien', 'satr', 'santi', 'sante', 'santen', 'sarti', 'sartis', 'sarin', 'sarn', 'stu', 'stur', 'stul', 'stus', 'stui', 'stuc', 'sta', 'stal', 'stali', 'stalin', 'stan', 'stari', 'starin', 'sti', 'stil', 'stic', 'stira', 'stin', 'str', 'stran', 'stri', 'stric', 'strin', 'strei', 'strec', 'stren', 'ste', 'stei', 'steir', 'stec', 'ster', 'stera', 'steril', 'sternali', 'steni', 'stenc', 'stenci', 'll', 'lures', 'lus', 'lusi', 'lusit', 'lusita', 'lusitan', 'lusc', 'lusci', 'luscin', 'luta', 'lutan', 'luti', 'lutis', 'lutin', 'lutr', 'lutri', 'lutre', 'lutei', 'lutec', 'luteci', 'lui', 'luis', 'luise', 'luit', 'luc', 'luci', 'lucit', 'lucin', 'lucer', 'lucerna', 'lucen', 'lasqu', 'lasti', 'lastin', 'lastn', 'lastr', 'laste', 'latu', 'lati', 'latis', 'latise', 'latic', 'latice', 'latir', 'latine', 'latr', 'latri', 'latrin', 'latre', 'latec', 'lateri', 'lateric', 'latericu', 'laterin', 'latenc', 'lantu', 'lante', 'lanter', 'larit', 'laric', 'larn', 'lare', 'laren', 'liu', 'liser', 'lisu', 'lits', 'litu', 'litur', 'lita', 'litan', 'litr', 'litera', 'lic', 'licu', 'lice', 'licen', 'lir', 'lirat', 'liern', 'lienc', 'liencu', 'linc', 'linec', 'linecu', 'ures', 'uresi', 'url', 'urla', 'urli', 'urlin', 'urs', 'ursi', 'ursic', 'ursin', 'ue', 'ul', 'ulr', 'uls', 'ulst', 'ulste', 'ulsteri', 'ulsterin', 'ulat', 'ulatr', 'ult', 'ulti', 'ultr', 'ultras', 'ultran', 'ulte', 'ulter', 'ulteri', 'uli', 'ulit', 'usi', 'usit', 'usita', 'usin', 'uts', 'uti', 'util', 'utic', 'utin', 'utr', 'utra', 'utri', 'utric', 'utre', 'utrec', 'uter', 'utera', 'uteral', 'uterin', 'uten', 'ui', 'uil', 'uit', 'uits', 'uir', 'uin', 'uc', 'sr', 'sru', 'srut', 'seru', 'seu', 'su', 'surqu', 'surl', 'surli', 'surlin', 'surline', 'sul', 'sult', 'sulta', 'sultanr', 'sultr', 'sultri', 'sultrin', 'sultrine', 'suli', 'sut', 'sutl', 'suta', 'suti', 'sutil', 'sutr', 'sute', 'suter', 'suil', 'suill', 'suita', 'suic', 'suin', 'suc', 'suci', 'silu', 'silur', 'silure', 'sila', 'silan', 'silta', 'siu', 'situ', 'situl', 'sicu', 'sicul', 'sien', 'sinc', 'sincer', 'sinec', 'sinecu', 'sinecur', 'sc', 'scu', 'scul', 'sculs', 'scuti', 'sci', 'scil', 'scill', 'sciu', 'sciur', 'scit', 'scita', 'scir', 'scirt', 'scire', 'sciren', 'scie', 'scien', 'scin', 'sce', 'scer', 'scern', 'scen', 'sceni', 'scenit', 'asl', 'asqu', 'asl', 'aslu', 'astu', 'astuc', 'astuci', 'asti', 'astil', 'astic', 'astin', 'astr', 'astri', 'astril', 'astric', 'astrie', 'astrin', 'astre', 'aste', 'astei', 'asteis', 'asteri', 'asteris', 'all', 'alls', 'alqu', 'alr', 'alre', 'alru', 'als', 'alst', 'alstr', 'alu', 'alus', 'alut', 'aluc', 'alts', 'altu', 'alti', 'altis', 'altisc', 'altic', 'altinc', 'altr', 'altri', 'altric', 'altrice', 'alte', 'alteri', 'ali', 'aliu', 'alis', 'alise', 'alitu', 'alitur', 'alitr', 'alic', 'alie', 'aliet', 'alienc', 'atl', 'atu', 'atul', 'atil', 'atin', 'atn', 'atr', 'atri', 'atriu', 'atric', 'atrie', 'atrien', 'atre', 'atec', 'ater', 'ateri', 'ateni', 'atenis', 'ants', 'antl', 'antlu', 'antlue', 'antli', 'antlin', 'antil', 'antill', 'antilu', 'antilue', 'antiu', 'antiur', 'antiure', 'antius', 'antis', 'antise', 'antiser', 'antiseru', 'antisu', 'antisur', 'antisc', 'anticu', 'antice', 'anticer', 'anticen', 'anticn', 'anticne', 'antir', 'antire', 'antirec', 'antiren', 'antie', 'antiec', 'antier', 'antien', 'antin', 'antine', 'antr', 'antri', 'antrec', 'antei', 'antein', 'antec', 'antecu', 'antecur', 'anter', 'anteri', 'anten', 'artl', 'artli', 'arti', 'artil', 'artill', 'artis', 'artic', 'articu', 'articul', 'artin', 'artine', 'arte', 'ari', 'arill', 'ariu', 'aris', 'arit', 'aric', 'arie', 'ariet', 'arien', 'aret', 'areti', 'aretin', 'arei', 'areit', 'arec', 'arecu', 'aren', 'areni', 'arenil', 'arenic', 'ts', 'tsa', 'tsan', 'tsari', 'tsarin', 'tsare', 'tl', 'tla', 'tlas', 'tli', 'tlin', 'tuqu', 'turqu', 'ture', 'turl', 'turs', 'tursi', 'tues', 'tul', 'tull', 'tuls', 'tulas', 'tular', 'tuli', 'tulis', 'tus', 'tusc', 'tuil', 'tuill', 'tuis', 'tuc', 'tas', 'tasl', 'tasl', 'talu', 'taluc', 'talie', 'talier', 'talin', 'tanr', 'tanre', 'taris', 'taren', 'tils', 'tila', 'tilas', 'tis', 'ticu', 'tir', 'tira', 'tiral', 'tinc', 'tr', 'tras', 'tral', 'trall', 'trali', 'tran', 'tril', 'trilu', 'trila', 'triu', 'triur', 'tris', 'trise', 'triser', 'trisu', 'trisc', 'trisce', 'tric', 'tricu', 'tricur', 'tricus', 'tricen', 'trie', 'trien', 'tre', 'trei', 'treil', 'treill', 'trec', 'trecu', 'trecul', 'treculi', 'tren', 'trenc', 'tei', 'teic', 'teir', 'tein', 'tecu', 'tecn', 'ter', 'teni', 'tenc', 'il', 'isr', 'ise', 'iser', 'iseu', 'isu', 'isur', 'isure', 'isc', 'itu', 'itur', 'ital', 'ite', 'itera', 'iteran', 'ic', 'icer', 'icen', 'ir', 'iras', 'irat', 'iren', 'ier', 'iern', 'inc', 'incu', 'incurs', 'incul', 'ince', 'incer', 'incera', 'incerat', 'incert', 'ine', 'inet', 'inec', 'iner', 'inera', 'ineras', 'inertl', 'inerta', 'inertan', 'inertn', 'cu', 'curli', 'curlie', 'curlin', 'curline', 'curs', 'cursi', 'cursit', 'cuer', 'cues', 'cul', 'cula', 'culti', 'cultis', 'cultir', 'cultr', 'cultra', 'cultri', 'culte', 'culter', 'cultera', 'culteran', 'culi', 'culin', 'cus', 'cuse', 'cusi', 'cusin', 'cusine', 'cusiner', 'cutl', 'cutla', 'cutlas', 'cutli', 'cutlin', 'cuta', 'cutan', 'cuti', 'cutise', 'cutir', 'cutire', 'cuter', 'cuten', 'cui', 'cuis', 'cuit', 'cuitl', 'cuitla', 'cuira', 'cuiras', 'cuin', 'cs', 'ci', 'cil', 'cill', 'cis', 'cisr', 'citu', 'cita', 'citr', 'citra', 'citran', 'citre', 'citren', 'cir', 'cin', 'ciner', 'cinera', 'cinerat', 'cet', 'cetu', 'ceta', 'cetan', 'cetr', 'cetra', 'cei', 'cer', 'cera', 'cerast', 'cerasti', 'cerastiu', 'cerat', 'cerati', 'ceratiu', 'cert', 'certa', 'certi', 'ceri', 'ceril', 'cerill', 'ceriu', 'ceris', 'cerit', 'cen', 'cn', 'cni', 'cne', 'nas', 'nastu', 'nastur', 'nasti', 'nastil', 'nastin', 'nastine', 'nal', 'nall', 'nali', 'nalit', 'natu', 'natur', 'nati', 'natic', 'natri', 'natriu', 'natric', 'nate', 'nart', 'nari', 'narin', 'nare', 'nt', 'rast', 'rastl', 'rastu', 'rasti', 'raste', 'ral', 'rall', 'rals', 'ralst', 'rats', 'ratl', 'ratli', 'ratlin', 'rati', 'ratic', 'ratin', 'ranti', 'rantin', 'rante', 'ri', 'ril', 'rills', 'rillst', 'rila', 'ris', 'rits', 'ritl', 'ritu', 'ric', 'rin', 'rinc', 'rince', 'retu', 'retur', 'retus', 'retuc', 'reta', 'retas', 'retal', 'retali', 'reti', 'retil', 'retis', 'retic', 'reticu', 'reticul', 'retinc', 'rei', 'reil', 'reill', 'reic', 'reinc', 'reincu', 'reincul', 'rec', 'recu', 'recurs', 'recursi', 'recul', 'recult', 'reculti', 'recus', 'reci', 'recis', 'recit', 'recita', 'ren', 'reni', 'renil', 'renill', 'renis', 'renit', 'renic', 'renc', 'rencu', 'rencul', 'et', 'etu', 'etal', 'eti', 'etn', 'etr', 'ei', 'eil', 'eis', 'eise', 'eit', 'eic', 'eir', 'ein', 'ec', 'ecu', 'ecue', 'ecs', 'eci', 'ecil', 'ecit', 'eras', 'erast', 'erastu', 'erasti', 'eran', 'erant', 'ert', 'eri', 'eris', 'erit', 'erin', 'ern', 'eni', 'enis', 'enic', 'enicu', 'enicur', 'enc', 'encu', 'encur', 'encus', 'encui', 'encuir', 'encuira', 'encuiras', 'enci', 'encis', 'encit', 'encita', 'encir', 'niu', 'nis', 'nise', 'nisu', 'nitr', 'nitra', 'nitran', 'nite', 'nic', 'nicet', 'nir', 'nie', 'niet', 'niec', 'nier', 'nets', 'netl', 'netli', 'neill', 'neis', 'neit', 'nec', 'ner', 'nert', 'neriu', 'nerit']



One might ask, why is an O(length string) algorithm slower than O(log number of words in dictionary)?  Well, remember that these are the asymptotic running times of the algorithms; there are always constant factors at play which can cause a theoretically faster algorithm to perform worse in actuality.  Log2 of 200k is approximately 20, so the binary search does not have to do much work even in the worst case.  The trie uses nested dicts as opposed to the simple sorted list; this might add to the overhead as well.  Alternate implementations might very well beat out









This problem can be seen as a graph traversal.  The adjacency information can be encoded in a directed graph:

[A][B][C][D]
[E][F][G][H]
[I][J][K][L]
[M][N][O][P]

[
['a','b','c','d'],
['e','f','g','h'],
['i','j','k','l'],
['m','n','o','p'],
]

print "digraph boggle {"
for i in range(0, 4):
  for j in range(0, 4):
    for row_offset in (-1, 0, 1):
	  for col_offset in (-1, 0, 1):
	    if row_offset != 0 or col_offset != 0:
		  i2 = i + row_offset
		  j2 = j + col_offset
		  if 0 <= i2 < 4 and 0 <= j2 < 4:
		    print '"%s" -> "%s"' %(b[i][j], b[i2][j2])

print "}"					

# Basic algorithm
Here is the basic algorithm:


<div>
[sourcecode language="python"]

def Solve(self, board):
"""Returns a list of FoundWord objects."""
solutions = []

# Start an exhaustive search of the board
for row in range(board.num_rows):
  for col in range(board.num_cols):
    loc = Location(row, col)
    previous_locs = []
    solutions.extend(self.DoSolve(board, previous_locs, loc, ''))

return solutions

def DoSolve(self, board, previous_locations, location, word_prefix):
	"""Returns iterable of FoundWord objects.

	Args:
	  previous_locations: a list of already visited locations
	  location: the current Location from where to start searching
	  word_prefix: the current word built up so far, as a string
	"""
	solutions = []

	new_word = word_prefix + board[location.row][location.col]
	previous_locations.append(location)

	# Huge optimization - fail fast and prune out a large portion
	# of the search space
	if not self.HasPrefix(new_word):
	  if DEBUG:
	    print 'No words found starting with "%s"' %(new_word)
	  return solutions

	# This is a valid, complete words.
	if self.IsWord(new_word):
	  new_solution = FoundWord(new_word, previous_locations)
	  if DEBUG:
	    print 'Found new solution: %s' %(str(new_solution))
	  solutions.append(new_solution)

	# Recursively search all adjacent tiles
	for new_loc in location.Adjacent():
	  if board.IsValidLocation(new_loc) and new_loc not in previous_locations:
	    # make a copy of the previous locations list so our current list
	    # is not affected by this recursive call.
	    defensive_copy = list(previous_locations)
	    solutions.extend(self.DoSolve(board, defensive_copy, new_loc, new_word))
	  else:
	    if DEBUG:
	      print 'Ignoring %s as it is invalid or already used.' %(str(new_loc))

	return solutions
[/sourcecode]
</div>

The two calls which are reliant on the word storage data structures and algorithms are `if not self.HasPrefix(new_word)` and `self.IsWord(new_word)`.  While the search technically would work without 



# Naiive solution
unsorted list

prefix search - for every word, check if it starts with
linear search

O(n*m) prefix search

Took 6544.000 seconds to solve 10 boards; avg 654.443 with <__main__.UnsortedListBoardSolver object at 0x135add0>
Took 7246.000 seconds to solve 10 boards; avg 724.652 with <__main__.TrieBoardSolver object at 0x135acf0>
Took 7710.000 seconds to solve 10 boards; avg 771.001 with <__main__.SortedListBoardSolver object at 0x135adf0>



# Trie solution
trie data structure - O(m)


# Conclusion

I was very surprised to see how  much more performant the sorted list / bisection approach was than the trie.  Then I remembered the all important constant factors portion of big o notation.  While the trie should be faster as the size of the words increases astronomically,..

with a dictionary of 270k words, the sorted list approach has to examine at most ~20 words to find a math



Took 182.000 seconds to solve 1 boards; avg 182.711 with <__main__.UnsortedListBoardSolver object at 0x198c870>
Took 1.000 seconds to solve 1 boards; avg 1.834 with <__main__.TrieBoardSolver object at 0x198c790>
Took 0.000 seconds to solve 1 boards; avg 0.028 with <__main__.SortedListBoardSolver object at 0x198c890>


I was generating huge result sets and then checking if there was at least one entry rather than bypassing all the extra work
def HasPrefix(self, prefix):
  # Bug
  return len(self.trie.find_prefix_matches(prefix)) > 0



Size of trie solver pickled: 14429374
Size of list solver pickled: 3878681
Size of sorted list solver pickled: 3878645

wtf why is the trie one biggest?  I guess the dictionaries take some space

234936 /usr/share/dict/words

Size of trie solver pickled: 14429374
Size of list solver pickled: 3878681
Size of sorted list solver pickled: 3878645


Took 0.000 seconds to solve 10 boards; avg 0.031 with <__main__.TrieBoardSolver object at 0x135acf0>
Took 0.000 seconds to solve 10 boards; avg 0.030 with <__main__.SortedListBoardSolver object at 0x135adf0>
Took 2.000 seconds to solve 100 boards; avg 0.023 with <__main__.TrieBoardSolver object at 0x135acf0>
Took 2.000 seconds to solve 100 boards; avg 0.024 with <__main__.SortedListBoardSolver object at 0x135adf0>
Took 33.000 seconds to solve 1000 boards; avg 0.034 with <__main__.TrieBoardSolver object at 0x135acf0>
Took 24.000 seconds to solve 1000 boards; avg 0.025 with <__main__.SortedListBoardSolver object at 0x135adf0>

$ python2.6 scramble_solver/solver.py scramble_solver/sampled.dict 
Size of trie solver pickled: 34377
Size of list solver pickled: 3274
Size of sorted list solver pickled: 3247
Took 0.000 seconds to solve 10 boards; avg 0.005 with <__main__.TrieBoardSolver object at 0xfbc90>
Took 0.000 seconds to solve 10 boards; avg 0.005 with <__main__.SortedListBoardSolver object at 0xfbd30>
Took 0.000 seconds to solve 100 boards; avg 0.004 with <__main__.TrieBoardSolver object at 0xfbc90>
Took 0.000 seconds to solve 100 boards; avg 0.004 with <__main__.SortedListBoardSolver object at 0xfbd30>
Took 3.000 seconds to solve 1000 boards; avg 0.004 with <__main__.TrieBoardSolver object at 0xfbc90>
Took 3.000 seconds to solve 1000 boards; avg 0.004 with <__main__.SortedListBoardSolver object at 0xfbd30>
Took 40.000 seconds to solve 10000 boards; avg 0.004 with <__main__.TrieBoardSolver object at 0xfbc90>
Took 37.000 seconds to solve 10000 boards; avg 0.004 with <__main__.SortedListBoard

awk '{if (NR % 1000 == 0) print $0} ' /usr/share/dict/words > scramble_solver/sampled.dict



# The Naive / Brute Force Solution

Just for fun, let's imagine the most mind-numbingly stupid way possible of solving it - by enumerating each possible permutation of letters and filtering out the non-word combinations.  What is the approximate running time of that algorithm?

Well, you can imagine a decision tree of possibilities.  At the root would be a tile, under it would be up to 4 possibilities, under it would be up to 3 possibilities, and so on and so forth up to a maximum depth of 16.  This represents all the possible character strings which can be made starting from a given tile.  There would be 16 such trees, one for each starting position.

As a very approximate upper bound, this tree would have size 



1 -> 1
2x2 -> 64
3x3 -> 10305



I will first illustrate a brute force, recursive solution in Python.  As you probably remember, recursion is simply when a method calls itself.  In order to avoid an infinite loop (and eventual stack overflow), there must be some sort of stopping criteria.  Before moving on to the code, here's the basic strategy:

	Start search at a given point on the board
	Examine square
		If the entire word built up so far is a word, add it to list
		If the word built up so far + the new letter starts at least one word in the dictionary
			Recursively search all squares around this one, ensuring that we neither go off the board nor reuse a square
		
## Data structures

The data structure you choose has a huge effect on the runtime of the algorithm.  
		
		
## Optimization
This algorithm works but it is extremely inefficient.  Why?  For each square we examine, we need to examine the entire dictionary (all M words) and do a 'startswith' check on all of them

O(n)

Wouldn't it make more sense to eliminate a large number of words?



## Tries




# Trie results


# Can we do better?
Tries are a huge improvement over a naive list or dict data structure, but they are not optimal for space purposes.


# DAWG
[Directed acyclic word graph][]


"The primary difference between DAWG and trie is the elimination of suffix redundancy in storing strings. The trie eliminates prefix redundancy since all common prefixes are shared between strings, such as between doctors and doctorate the doctor prefix is shared. In a DAWG common suffixes are also shared, such as between desertion and destruction both the prefix des- and suffix -tion are shared. For dictionary sets of common English words, this translates into major memory usage reduction.
Because the terminal nodes of a DAWG can be reached by multiple paths, a DAWG cannot directly store auxiliary information relating to each path, e.g. a word's frequency in the English language. However, if at each node we store a count of the number of unique paths through the structure from that point, we can use it to retrieve the index of a word, or a word given its index.[1] The auxiliary information can then be stored in an array" -- [Directed acyclic word graph][]





# Conclusion
We have seen how using the correct data structure (trie) makes an enormous difference when it comes to runtime performance.  

We have also seen how recursion makes it very succint to express an algorithm that otherwise would be very complicated

We have also seen how to replace a recursive implementation with an explicit stack based, iterative approach.



[Trie wikipedia]:http://en.wikipedia.org/wiki/Trie
[Directed acyclic word graph]:http://en.wikipedia.org/wiki/Directed_acyclic_word_graph
[fast scrabble solver]:http://www.cs.cmu.edu/afs/cs/academic/class/15451-s06/www/lectures/scrabble.pdf
[Compressiong dictionaries with a DAWG: dawg in python]:http://stevehanov.ca/blog/index.php?id=115
[wordutils dawg]:http://pypi.python.org/pypi/WordUtils/0.8.0
[extremely space efficient dawg]:http://www.wutka.com/dawg.html
[Scramble screenshot]:https://lh4.googleusercontent.com/-3QH0bUh55U0/T78dRCJgbnI/AAAAAAAACVc/ugRCRZjTnSc/s512/scramble_board.jpg
[Recursion]:http://en.wikipedia.org/wiki/Recursion
[Depth first search]:http://www.cs.toronto.edu/~heap/270F02/node36.html
[Binary search]:http://en.wikipedia.org/wiki/Binary_search_algorithm
[binary search blog post]:http://reprog.wordpress.com/2010/04/19/are-you-one-of-the-10-percent/
[bisect module]:http://docs.python.org/library/bisect.html
[Python trie implementation]:https://bitbucket.org/woadwarrior/trie/src/6bc187d770ba/python/trie.py